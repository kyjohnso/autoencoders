{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.layers import (Lambda, Input, Reshape,\n",
    "                          Dense, UpSampling2D,\n",
    "                          Conv2D, Concatenate,\n",
    "                          Flatten, MaxPool2D,)\n",
    "from keras.losses import mse, mae, binary_crossentropy\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def settrainable(model, toset):\n",
    "    for layer in model.layers:\n",
    "        layer.trainable = toset\n",
    "    model.trainable = toset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 256, 8, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 256, 8, 32)   320         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 128, 4, 32)   0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 128, 4, 32)   9248        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 64, 2, 32)    0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 64, 2, 32)    9248        max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 32, 1, 32)    0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 1024)         0           max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "features (Dense)                (None, 50)           51250       flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "classes (Dense)                 (None, 8)            8200        flatten_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 78,266\n",
      "Trainable params: 78,266\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_shape = (256,8,1) # (nfft,n_lookback,n_channels)\n",
    "filters = [32,32,32]\n",
    "layers = 3\n",
    "kernel_size = [3,3]\n",
    "pool_size = [2,2]\n",
    "intermediate = 16\n",
    "latent_dim = 50\n",
    "n_classes = 8\n",
    "\n",
    "inputs = Input(shape=input_shape)\n",
    "x = inputs\n",
    "for i in range(layers):\n",
    "    x = Conv2D(filters[i],\n",
    "               kernel_size=kernel_size,\n",
    "               activation='relu',\n",
    "               padding='same')(x)\n",
    "    x = MaxPool2D(pool_size=pool_size)(x)\n",
    "\n",
    "\n",
    "# shape info needed to build decoder model\n",
    "shape = K.int_shape(x)\n",
    "\n",
    "x = Flatten()(x)\n",
    "# generate latent vector Q(z|X)\n",
    "features = Dense(latent_dim, activation='linear',name='features')(x)\n",
    "classes = Dense(n_classes, activation='softmax',name='classes')(x)\n",
    "\n",
    "# no reparameterization trick here, since we will get the distribution\n",
    "#   through adversarial training against a stocastic process we don't\n",
    "#   need to sample here\n",
    "\n",
    "encoder = Model(inputs, [features,classes], name='encoder')\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "decoder_input (InputLayer)   (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              52224     \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 32, 1, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 32, 1, 32)         9248      \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 64, 2, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 64, 2, 64)         18496     \n",
      "_________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2 (None, 128, 4, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 128, 4, 64)        36928     \n",
      "_________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2 (None, 256, 8, 64)        0         \n",
      "_________________________________________________________________\n",
      "decoder_output (Conv2D)      (None, 256, 8, 1)         577       \n",
      "=================================================================\n",
      "Total params: 117,473\n",
      "Trainable params: 117,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "filters = [32,64,64]\n",
    "upsampling_size = pool_size\n",
    "\n",
    "latent_inputs = Input(shape=(latent_dim,), name='decoder_input')\n",
    "# latent_inputs = Input(shape=(latent_dim+n_classes,), name='decoder_input')\n",
    "x = Dense(shape[1] * shape[2] * shape[3], activation='relu')(latent_inputs)\n",
    "x = Reshape((shape[1], shape[2], shape[3]))(x)\n",
    "\n",
    "for i in range(layers):\n",
    "    x = Conv2D(filters=filters[i],\n",
    "               kernel_size=kernel_size,\n",
    "               activation='relu',\n",
    "               padding='same')(x)\n",
    "    x = UpSampling2D(size=upsampling_size)(x)\n",
    "\n",
    "x = Conv2D(filters=1,\n",
    "           kernel_size=kernel_size,\n",
    "           activation='relu',\n",
    "           padding='same',\n",
    "           name='decoder_output')(x)\n",
    "\n",
    "outputs=x\n",
    "\n",
    "decoder = Model(latent_inputs,outputs)\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the discriminators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "disc_input (InputLayer)      (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               13056     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 79,105\n",
      "Trainable params: 79,105\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "disc_dim = 256\n",
    "feat_disc_inputs = Input(shape=(latent_dim,), name='disc_input')\n",
    "x = feat_disc_inputs\n",
    "x = Dense(disc_dim, activation='relu')(x)\n",
    "x = Dense(disc_dim, activation='relu')(x)\n",
    "feat_disc_outputs = Dense(1,activation='sigmoid')(x)\n",
    "\n",
    "feat_disc = Model(feat_disc_inputs,feat_disc_outputs,name='feat_disc')\n",
    "feat_disc.compile(optimizer=Adam(lr=1e-4), \n",
    "                      loss=\"binary_crossentropy\")\n",
    "feat_disc.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "disc_input (InputLayer)      (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 256)               2304      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 68,353\n",
      "Trainable params: 68,353\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "disc_dim = 256\n",
    "class_disc_inputs = Input(shape=(n_classes,), name='disc_input')\n",
    "x = class_disc_inputs\n",
    "x = Dense(disc_dim, activation='relu')(x)\n",
    "x = Dense(disc_dim, activation='relu')(x)\n",
    "class_disc_outputs = Dense(1,activation='sigmoid')(x)\n",
    "\n",
    "class_disc = Model(class_disc_inputs,class_disc_outputs,name='class_disc')\n",
    "class_disc.compile(optimizer=Adam(lr=1e-4), \n",
    "                      loss=\"binary_crossentropy\")\n",
    "class_disc.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define composite models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 256, 8, 1)         0         \n",
      "_________________________________________________________________\n",
      "encoder (Model)              [(None, 50), (None, 8)]   78266     \n",
      "_________________________________________________________________\n",
      "model_1 (Model)              (None, 256, 8, 1)         117473    \n",
      "=================================================================\n",
      "Total params: 195,739\n",
      "Trainable params: 195,739\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "outputs = decoder(encoder(inputs)[0])\n",
    "# outputs = decoder(Concatenate(axis=-1)(encoder(inputs)))\n",
    "ae = Model(inputs, outputs, name='ae')\n",
    "ae.compile(optimizer=Adam(lr=1e-4), \n",
    "           loss=\"binary_crossentropy\")\n",
    "ae.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 256, 8, 1)         0         \n",
      "_________________________________________________________________\n",
      "encoder (Model)              [(None, 50), (None, 8)]   78266     \n",
      "_________________________________________________________________\n",
      "feat_disc (Model)            (None, 1)                 79105     \n",
      "=================================================================\n",
      "Total params: 157,371\n",
      "Trainable params: 157,371\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "feat_disc_output = feat_disc(encoder(inputs)[0])\n",
    "enc_feat_disc = Model(inputs,feat_disc_output,name='enc_feat_disc')\n",
    "enc_feat_disc.compile(optimizer=Adam(lr=1e-4), \n",
    "                      loss=\"binary_crossentropy\")\n",
    "enc_feat_disc.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 256, 8, 1)         0         \n",
      "_________________________________________________________________\n",
      "encoder (Model)              [(None, 50), (None, 8)]   78266     \n",
      "_________________________________________________________________\n",
      "class_disc (Model)           (None, 1)                 68353     \n",
      "=================================================================\n",
      "Total params: 146,619\n",
      "Trainable params: 146,619\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "class_disc_output = class_disc(encoder(inputs)[1])\n",
    "enc_class_disc = Model(inputs,class_disc_output,name='enc_class_disc')\n",
    "enc_class_disc.compile(optimizer=Adam(lr=1e-4), \n",
    "                      loss=\"binary_crossentropy\")\n",
    "enc_class_disc.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "define sampling procedures for the latent feature and class distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_classes(labels,n_classes=None):\n",
    "    if n_classes == None:\n",
    "        n_classes = np.max(labels)\n",
    "    ulabel = labels == -1\n",
    "    labels[ulabel] = np.random.randint(0,n_classes,np.sum(ulabel))\n",
    "    labels = labels.astype(int)\n",
    "    oh = np.zeros((labels.shape[0],n_classes),dtype=int)\n",
    "    oh[range(labels.shape[0]),labels]=1\n",
    "    return oh\n",
    "\n",
    "def sample_features(n_samples,n_dimensions):\n",
    "    return np.random.multivariate_normal(np.zeros(n_dimensions),np.eye(n_dimensions),n_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 10000\n",
    "X = np.random.uniform(0,1,(n_samples,)+input_shape)\n",
    "X_train, X_test = train_test_split(X,train_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "An operation has `None` for gradient. Please make sure that all of your ops have a gradient defined (i.e. are differentiable). Common ops without gradient: K.argmax, K.round, K.eval.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-108b11e41828>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;31m# first perform reconstruction training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;31m# now perform regularization training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1214\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1216\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1217\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_make_train_function\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    507\u001b[0m                     training_updates = self.optimizer.get_updates(\n\u001b[1;32m    508\u001b[0m                         \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_collected_trainable_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 509\u001b[0;31m                         loss=self.total_loss)\n\u001b[0m\u001b[1;32m    510\u001b[0m                 updates = (self.updates +\n\u001b[1;32m    511\u001b[0m                            \u001b[0mtraining_updates\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/optimizers.py\u001b[0m in \u001b[0;36mget_updates\u001b[0;34m(self, loss, params)\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_updates_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_updates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m         \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_add\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/optimizers.py\u001b[0m in \u001b[0;36mget_gradients\u001b[0;34m(self, loss, params)\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrads\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m             raise ValueError('An operation has `None` for gradient. '\n\u001b[0m\u001b[1;32m     92\u001b[0m                              \u001b[0;34m'Please make sure that all of your ops have a '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m                              \u001b[0;34m'gradient defined (i.e. are differentiable). '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: An operation has `None` for gradient. Please make sure that all of your ops have a gradient defined (i.e. are differentiable). Common ops without gradient: K.argmax, K.round, K.eval."
     ]
    }
   ],
   "source": [
    "epochs = 1\n",
    "batch_size = 1000\n",
    "for i_epoch in range(epochs):\n",
    "    np.random.shuffle(X_train)\n",
    "    \n",
    "    for i_batch in range(int(X_train.shape[0]/batch_size)):\n",
    "        settrainable(ae, True)\n",
    "        settrainable(encoder, True)\n",
    "        settrainable(decoder, True)\n",
    "        \n",
    "        batch = X_train[i_batch*batch_size:(i_batch+1)*batch_size]\n",
    " \n",
    "        # first perform reconstruction training\n",
    "        ae.train_on_batch(batch,batch)\n",
    "        \n",
    "        # now perform regularization training\n",
    "        settrainable(feat_disc, True)\n",
    "        batch_features = encoder.predict(batch)[0]\n",
    "        fake_features = sample_features(batch_size,latent_dim,)\n",
    "        \n",
    "        # now train the feat_disc giving it ones for true, and \n",
    "        #     zeros for fake\n",
    "        discbatch_x = np.concatenate([batch_features,fake_features])\n",
    "        discbatch_y = np.concatenate([np.ones(batch_size),\n",
    "                                      np.zeros(batch_size)])\n",
    "        feat_disc.train_on_batch(discbatch_x,discbatch_y)\n",
    "        \n",
    "        # now train the enc_feat_disc but only update the \n",
    "        #     encoder weights and try to fool the discriminator\n",
    "        settrainable(enc_feat_disc, True)\n",
    "        settrainable(encoder, True)\n",
    "        settrainable(feat_disc, False)\n",
    "        enc_feat_disc.train_on_batch(batch, np.ones(batch_size))\n",
    "        \n",
    "        # now perform semi-supervised training\n",
    "        settrainable(class_disc, True)\n",
    "        batch_classes = encoder.predict(batch)[1]\n",
    "        fake_classes = sample_classes(np.ones(batch_size)*-1,n_classes,)\n",
    "        \n",
    "        # now train the class_disc giving it ones for true, and \n",
    "        #     zeros for fake\n",
    "        discbatch_x = np.concatenate([batch_classes,fake_classes])\n",
    "        discbatch_y = np.concatenate([np.ones(batch_size),\n",
    "                                      np.zeros(batch_size)])\n",
    "        class_disc.train_on_batch(discbatch_x,discbatch_y)\n",
    "        \n",
    "        # now train the enc_class_disc but only update the \n",
    "        #     encoder weights and try to fool the discriminator\n",
    "        settrainable(enc_class_disc, True)\n",
    "        settrainable(encoder, True)\n",
    "        settrainable(class_disc, False)\n",
    "        enc_class_disc.train_on_batch(batch, np.ones(batch_size))\n",
    "        \n",
    "        print(\"Reconstruction Loss:\", \n",
    "                  ae.evaluate(X_train, X_train, verbose=0))\n",
    "        \n",
    "        print(\"Feature Adversarial Loss:\", \n",
    "                  enc_feat_disc.evaluate(X_train, \n",
    "                                         np.ones(X_train.shape[0]),\n",
    "                                         verbose=0))\n",
    "        print(\"Class Adversarial Loss:\", \n",
    "                  enc_class_disc.evaluate(X_train, \n",
    "                                          np.ones(X_train.shape[0]),\n",
    "                                          verbose=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
