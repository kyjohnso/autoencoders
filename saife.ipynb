{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.layers import (Lambda, Input, Reshape,\n",
    "                          Dense, LSTM,\n",
    "                          Conv2D, Conv2DTranspose,\n",
    "                          Flatten, MaxPool2D,\n",
    "                          Softmax,)\n",
    "from keras.losses import mse, mae, binary_crossentropy\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def settrainable(model, toset):\n",
    "    for layer in model.layers:\n",
    "        layer.trainable = toset\n",
    "    model.trainable = toset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The LSTM based encoder below with input_shape = (64,6),\n",
    "                                  layers = 1,\n",
    "                                  intermediate = 512,\n",
    "                                  latent_dim = n_classes = 4,\n",
    "\n",
    "is the closest to SAIFE that I can figure out from the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_14 (InputLayer)           (None, 64, 6)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_21 (LSTM)                  (None, 512)          1062912     input_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "features (Dense)                (None, 4)            2052        lstm_21[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "classes (Dense)                 (None, 4)            2052        lstm_21[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 1,067,016\n",
      "Trainable params: 1,067,016\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_shape = (64,6) # (nfft)\n",
    "layers = 1\n",
    "intermediate = 512\n",
    "latent_dim = 4\n",
    "n_classes = latent_dim\n",
    "\n",
    "inputs = Input(shape=input_shape)\n",
    "x = inputs\n",
    "\n",
    "for layer in range(layers):\n",
    "    if layer+1 == layers:\n",
    "        x = LSTM(intermediate,activation='relu',return_sequences=False)(x)\n",
    "    else:\n",
    "        x = LSTM(intermediate,activation='relu',return_sequences=True)(x)\n",
    "        \n",
    "features = Dense(latent_dim,activation='linear',name='features')(x)\n",
    "classes = Dense(n_classes,activation='softmax',name='classes')(x)\n",
    "# no reparameterization trick here, since we will get the distribution\n",
    "#   through adversarial training against a stocastic process we don't\n",
    "#   need to sample here\n",
    "\n",
    "encoder = Model(inputs, [features,classes], name='encoder')\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "decoder_input (InputLayer)   (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1024)              5120      \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 256, 1, 4)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 512, 2, 4)         404       \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTr (None, 1024, 4, 2)        202       \n",
      "_________________________________________________________________\n",
      "decoder_output (Conv2DTransp (None, 1024, 4, 1)        51        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 1024, 1, 1)        0         \n",
      "=================================================================\n",
      "Total params: 5,777\n",
      "Trainable params: 5,777\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_shape = (64,6) # if you want 1D fft inputs, make the input_shape (nfft,1)\n",
    "layers = 3\n",
    "kernel_size = [5,5]\n",
    "strides = [2,2]\n",
    "dilation = [1,1]\n",
    "intermediate = 512\n",
    "latent_dim = 4\n",
    "\n",
    "latent_inputs = Input(shape=(latent_dim,), name='decoder_input')\n",
    "x = Dense(shape[1] * shape[2] * shape[3], activation='relu')(latent_inputs)\n",
    "x = Reshape((shape[1], shape[2], shape[3]))(x)\n",
    "\n",
    "for i in range(layers):\n",
    "    x = Conv2DTranspose(filters=filters,\n",
    "                        kernel_size=kernel_size,\n",
    "                        strides=strides,\n",
    "                        activation='relu',\n",
    "                        padding='same')(x)\n",
    "    filters //= 2\n",
    "\n",
    "x = Conv2DTranspose(filters=1,\n",
    "                    kernel_size=kernel_size,\n",
    "                    activation='relu', # we may need to play with this, the keras example has sigmoid\n",
    "                    padding='same',\n",
    "                    name='decoder_output')(x)\n",
    "\n",
    "# if 1D input we need to maxpool dim 2 to collapse the extra bins the Transpose conv2D put in that dimension\n",
    "if input_shape[1]==1:\n",
    "    out_shape = K.int_shape(x)\n",
    "    outputs = MaxPool2D(pool_size=(1,out_shape[2]), strides=None, padding='valid')(x)\n",
    "else:\n",
    "    outputs = x\n",
    "\n",
    "decoder = Model(latent_inputs,outputs)\n",
    "decoder.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "disc_input (InputLayer)      (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 32)                160       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 1,249\n",
      "Trainable params: 1,249\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "disc_dim = 32\n",
    "disc_inputs = Input(shape=(latent_dim,), name='disc_input')\n",
    "x = disc_inputs\n",
    "x = Dense(disc_dim, activation='relu')(x)\n",
    "x = Dense(disc_dim, activation='relu')(x)\n",
    "disc_outputs = Dense(1,activation='sigmoid')(x)\n",
    "\n",
    "discriminator = Model(disc_inputs,disc_outputs)\n",
    "discriminator.compile(optimizer=Adam(lr=1e-4), \n",
    "                      loss=\"binary_crossentropy\")\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define composite models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 1024, 1, 1)        0         \n",
      "_________________________________________________________________\n",
      "encoder (Model)              (None, 4)                 16724     \n",
      "_________________________________________________________________\n",
      "model_1 (Model)              (None, 1024, 1, 1)        5777      \n",
      "=================================================================\n",
      "Total params: 22,501\n",
      "Trainable params: 22,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "outputs = decoder(encoder(inputs))\n",
    "ae = Model(inputs, outputs, name='ae')\n",
    "ae.compile(optimizer=Adam(lr=1e-3), \n",
    "           loss=\"binary_crossentropy\")\n",
    "ae.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 1024, 1, 1)        0         \n",
      "_________________________________________________________________\n",
      "encoder (Model)              (None, 4)                 16724     \n",
      "_________________________________________________________________\n",
      "model_2 (Model)              (None, 1)                 1249      \n",
      "=================================================================\n",
      "Total params: 17,973\n",
      "Trainable params: 17,973\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "labels = discriminator(encoder(inputs))\n",
    "enc_disc = Model(inputs,labels,name='enc_disc')\n",
    "enc_disc.compile(optimizer=Adam(lr=1e-4), \n",
    "                 loss=\"binary_crossentropy\")\n",
    "enc_disc.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 10000\n",
    "X = np.random.uniform(0,1,(n_samples,)+input_shape)\n",
    "X_train, X_test = train_test_split(X,train_size=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/keras/engine/training.py:490: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reconstruction Loss: 2.991969310506185\n",
      "Adversarial Loss: 0.6893415473620097\n",
      "Reconstruction Loss: 2.715244542312622\n",
      "Adversarial Loss: 0.6873656316121419\n",
      "Reconstruction Loss: 2.562117127609253\n",
      "Adversarial Loss: 0.6854145938555399\n",
      "Reconstruction Loss: 2.4570766058603923\n",
      "Adversarial Loss: 0.6833689728101094\n",
      "Reconstruction Loss: 2.3773221271514893\n",
      "Adversarial Loss: 0.6812911276181539\n",
      "Reconstruction Loss: 2.3129668285369873\n",
      "Adversarial Loss: 0.6791802398999532\n",
      "Reconstruction Loss: 2.2588912197113036\n",
      "Adversarial Loss: 0.677025761381785\n"
     ]
    }
   ],
   "source": [
    "epochs = 1\n",
    "batch_size = 1000\n",
    "for i_epoch in range(epochs):\n",
    "    np.random.shuffle(X_train)\n",
    "    \n",
    "    for i_batch in range(int(X_train.shape[0]/batch_size)):\n",
    "        settrainable(ae, True)\n",
    "        settrainable(encoder, True)\n",
    "        settrainable(decoder, True)\n",
    "        \n",
    "        batch = X_train[i_batch*batch_size:(i_batch+1)*batch_size]\n",
    " \n",
    "        # first train the autoencoder\n",
    "        ae.train_on_batch(batch,batch)\n",
    "        \n",
    "        settrainable(discriminator, True)\n",
    "        batchpred = encoder.predict(batch)\n",
    "        fakepred = np.random.normal(0,1,(batch_size,latent_dim,))\n",
    "        \n",
    "        # now train the discriminator giving it ones for true, and \n",
    "        #     zeros for fake\n",
    "        discbatch_x = np.concatenate([batchpred,fakepred])\n",
    "        discbatch_y = np.concatenate([np.ones(batch_size),\n",
    "                                      np.zeros(batch_size)])\n",
    "        discriminator.train_on_batch(discbatch_x,discbatch_y)\n",
    "        \n",
    "        # now train the encoder descriminator but only update the \n",
    "        #     encoder weights and try to fool the discriminator\n",
    "        settrainable(enc_disc, True)\n",
    "        settrainable(encoder, True)\n",
    "        settrainable(discriminator, False)\n",
    "        enc_disc.train_on_batch(batch, np.ones(batch_size))\n",
    "        \n",
    "        print(\"Reconstruction Loss:\", \n",
    "                  ae.evaluate(X_train, X_train, verbose=0))\n",
    "        print(\"Adversarial Loss:\", \n",
    "                  enc_disc.evaluate(X_train, \n",
    "                                    np.ones(X_train.shape[0]),\n",
    "                                    verbose=0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
